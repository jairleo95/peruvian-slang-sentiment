{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "#from finetune_vs_scratch.preprocessing import special_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "import evaluate\n",
    "import numpy as np\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "special_tokens = [\"@usuario\", \"url\", \"hashtag\", \"emoji\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb1a6a937d684963ae0e74858a400cc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "model_name = 'dccuchile/bert-base-spanish-wwm-uncased'\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=3\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.model_max_length = 128\n",
    "tokenizer.add_tokens(special_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "f1_metric = evaluate.load(\"f1\")\n",
    "recall_metric = evaluate.load(\"recall\")\n",
    "\n",
    "def compute_metrics (eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis = -1)\n",
    "    \n",
    "    results = {}\n",
    "    results.update(f1_metric.compute(predictions=preds, references = labels, average=\"macro\"))\n",
    "    results.update(recall_metric.compute(predictions=preds, references = labels, average=\"macro\"))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_files = {\"train\": \"data/train.csv\", \"validation\": \"data/val.csv\", \"test\": \"data/test.csv\"}\n",
    "ds = load_dataset(\"csv\", data_files=data_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label', 'label_name', 'tokenized_text', 'sent_token_length', 'sent_bert_token_length', 'char_count', 'Character Count'],\n",
       "        num_rows: 573\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label', 'label_name', 'tokenized_text', 'sent_token_length', 'sent_bert_token_length', 'char_count', 'Character Count'],\n",
       "        num_rows: 71\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label', 'label_name', 'tokenized_text', 'sent_token_length', 'sent_bert_token_length', 'char_count', 'Character Count'],\n",
       "        num_rows: 64\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label to name\n",
    "def label2name(x):\n",
    "    if x == 0:\n",
    "        return \"Negative\"\n",
    "    if x == 1:\n",
    "        return \"Neutral\"\n",
    "    if x == 2:\n",
    "        return \"Positive\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': Value(dtype='string', id=None),\n",
       " 'label': Value(dtype='int64', id=None),\n",
       " 'label_name': Value(dtype='string', id=None),\n",
       " 'tokenized_text': Value(dtype='string', id=None),\n",
       " 'sent_token_length': Value(dtype='int64', id=None),\n",
       " 'sent_bert_token_length': Value(dtype='int64', id=None),\n",
       " 'char_count': Value(dtype='int64', id=None),\n",
       " 'Character Count': Value(dtype='int64', id=None)}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[\"train\"].features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pysentimiento.preprocessing import preprocess_tweet\n",
    "preprocessed_ds = ds.map(lambda ex: {\"text\": preprocess_tweet(ex[\"text\"], lang=\"es\")})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72fe1d6f5e3b4a129318b593722e11be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/573 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6369b0928884ed8adebda9913e23f23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/71 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2dd95c79a6a1433cbcd4689f859f39d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/64 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_ds = preprocessed_ds.map(\n",
    "    lambda batch: tokenizer(\n",
    "        batch[\"text\"], padding=True, truncation=True\n",
    "        ),\n",
    "    batched=True, batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer, DataCollatorWithPadding\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    per_device_train_batch_size=32,\n",
    "    output_dir=\"test_trainer\",\n",
    "    do_eval=True,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    num_train_epochs=5,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_ds[\"train\"],\n",
    "    eval_dataset=tokenized_ds[\"validation\"],\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9116514921188354, 'eval_f1': 0.394524959742351, 'eval_recall': 0.4385964912280702, 'eval_runtime': 0.1391, 'eval_samples_per_second': 510.573, 'eval_steps_per_second': 64.72, 'epoch': 1.0}\n",
      "{'eval_loss': 0.7890140414237976, 'eval_f1': 0.5445840069643079, 'eval_recall': 0.5313283208020051, 'eval_runtime': 0.137, 'eval_samples_per_second': 518.3, 'eval_steps_per_second': 65.7, 'epoch': 2.0}\n",
      "{'eval_loss': 0.871826171875, 'eval_f1': 0.5974774774774775, 'eval_recall': 0.587719298245614, 'eval_runtime': 0.134, 'eval_samples_per_second': 529.713, 'eval_steps_per_second': 67.147, 'epoch': 3.0}\n",
      "{'eval_loss': 0.9862819314002991, 'eval_f1': 0.5943019943019943, 'eval_recall': 0.587719298245614, 'eval_runtime': 0.1311, 'eval_samples_per_second': 541.542, 'eval_steps_per_second': 68.646, 'epoch': 4.0}\n",
      "{'eval_loss': 1.009502649307251, 'eval_f1': 0.6276668445343144, 'eval_recall': 0.6203007518796992, 'eval_runtime': 0.1309, 'eval_samples_per_second': 542.395, 'eval_steps_per_second': 68.754, 'epoch': 5.0}\n",
      "{'train_runtime': 23.7794, 'train_samples_per_second': 120.483, 'train_steps_per_second': 3.785, 'train_loss': 0.47921028137207033, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=90, training_loss=0.47921028137207033, metrics={'train_runtime': 23.7794, 'train_samples_per_second': 120.483, 'train_steps_per_second': 3.785, 'train_loss': 0.47921028137207033, 'epoch': 5.0})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.1125614643096924, 'eval_f1': 0.6377777777777779, 'eval_recall': 0.6184012066365008, 'eval_runtime': 0.1588, 'eval_samples_per_second': 402.97, 'eval_steps_per_second': 50.371, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.1125614643096924,\n",
       " 'eval_f1': 0.6377777777777779,\n",
       " 'eval_recall': 0.6184012066365008,\n",
       " 'eval_runtime': 0.1588,\n",
       " 'eval_samples_per_second': 402.97,\n",
       " 'eval_steps_per_second': 50.371,\n",
       " 'epoch': 5.0}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(tokenized_ds[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "955514ed-28d2-422e-8eca-56055de9bc39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de09e411",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af36065",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install torch==2.0.0\n",
    "#pip install pysentimiento==0.7.2\n",
    "#pip install evaluate==0.4.0\n",
    "#pip install datasets==2.14.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbffc10f-3389-44e6-b810-260a1d5415f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pysentimiento transformers datasets accelerate evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16f70f6-f93b-4be5-ac8a-33923bdf44af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1dcd6c81-eb73-4aa3-aa8c-ac9a46646d8b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-17 13:43:39.955768: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-17 13:43:39.990248: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-17 13:43:39.990274: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-17 13:43:39.991208: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-17 13:43:39.996803: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-17 13:43:40.630932: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce0ec026-0099-414e-a6bf-a76776f39c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9fbf152-07de-4cba-84b4-d3d871cb6eb3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a001ba7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ba02255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label to name\n",
    "def label2name(x):\n",
    "    if x == 0:\n",
    "        return \"Negative\"\n",
    "    if x == 1:\n",
    "        return \"Neutral\"\n",
    "    if x == 2:\n",
    "        return \"Positive\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d3164a0-faf4-4a4d-8a78-17b40b00c3f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "f1_metric = evaluate.load(\"f1\")\n",
    "recall_metric = evaluate.load(\"recall\")\n",
    "\n",
    "def compute_metrics (eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis = -1)\n",
    "    \n",
    "    results = {}\n",
    "    results.update(f1_metric.compute(predictions=preds, references = labels, average=\"macro\"))\n",
    "    results.update(recall_metric.compute(predictions=preds, references = labels, average=\"macro\"))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0bd8b7bc-ed54-4e65-ba9a-d2835b1abca8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Read Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "90c97202-c5c6-484f-850a-46a9ee552251",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_files = {\"train\": \"data/train.csv\", \"validation\": \"data/val.csv\", \"test\": \"data/test.csv\"}\n",
    "ds = load_dataset(\"csv\", data_files=data_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8087bffe-c868-4323-90f0-4c6951f4fb5c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label', 'label_name', 'tokenized_text', 'sent_token_length', 'sent_bert_token_length', 'char_count', 'Character Count'],\n",
       "        num_rows: 9133\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label', 'label_name', 'tokenized_text', 'sent_token_length', 'sent_bert_token_length', 'char_count', 'Character Count'],\n",
       "        num_rows: 1128\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label', 'label_name', 'tokenized_text', 'sent_token_length', 'sent_bert_token_length', 'char_count', 'Character Count'],\n",
       "        num_rows: 1015\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3ca4ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#push to hugging face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cbd1a339-fee4-41ef-8490-6b3e594e1a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65695826-cdf5-4338-a815-15b7de7f4abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://huggingface.co/settings/tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "32674b42-ff14-40e9-8400-6100827acdd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "710e1654ab68472b88972ff52ed35f44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "051a1e13-5030-4627-8a36-2326307dcf6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f64900f6db2c4480910d699060e86f3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pushing dataset shards to the dataset hub:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a250944f96144edca96d4f776cf643c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/10 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a74de375f154e279a421ab34731bb4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pushing dataset shards to the dataset hub:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc1617647cfa450180101c7f0ca06244",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92dd87a07dd34c08ac58850510499d4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pushing dataset shards to the dataset hub:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56072203c2e246f8812ef8161848fe3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds.push_to_hub(\"jairleo95/social-media-peruvian-sentiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e28595-3977-44f3-a9f0-9f62c1f3c802",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0c7abe81-d2ab-49c3-92bf-6c6e36d5d852",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': Value(dtype='string', id=None),\n",
       " 'label': Value(dtype='int64', id=None),\n",
       " 'label_name': Value(dtype='string', id=None),\n",
       " 'tokenized_text': Value(dtype='string', id=None),\n",
       " 'sent_token_length': Value(dtype='int64', id=None),\n",
       " 'sent_bert_token_length': Value(dtype='int64', id=None),\n",
       " 'char_count': Value(dtype='int64', id=None),\n",
       " 'Character Count': Value(dtype='int64', id=None)}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[\"train\"].features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a33842b-42eb-4966-8b48-f3dd7e1aeb33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 0, 0, 2, 1, 2, 0, 0, 1]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[\"test\"][\"label\"][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "68d24890",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>label_name</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>sent_token_length</th>\n",
       "      <th>sent_bert_token_length</th>\n",
       "      <th>char_count</th>\n",
       "      <th>Character Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nada como estar en lugares espectaculares, Man...</td>\n",
       "      <td>2</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Nada como estar en lugares espectaculares  Man...</td>\n",
       "      <td>18</td>\n",
       "      <td>24</td>\n",
       "      <td>118</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>La policÃ­a anda pensando que eres un subversivo</td>\n",
       "      <td>1</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>La policÃ­a anda pensando que eres un subversivo</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>47</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MAYRA GOÃ‘Y ...DEJALOS A TODOS EN PINDINGA!!! I...</td>\n",
       "      <td>0</td>\n",
       "      <td>Negative</td>\n",
       "      <td>MAYRA GOÃ‘Y    DEJALOS A TODOS EN PINDINGA    I...</td>\n",
       "      <td>10</td>\n",
       "      <td>19</td>\n",
       "      <td>62</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Vamos a poner a un huevÃ³n mÃ¡s y nos vamos</td>\n",
       "      <td>0</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Vamos a poner a un huevÃ³n mÃ¡s y nos vamos</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ExtraÃ±o las cachemas con yucas ðŸ˜”</td>\n",
       "      <td>1</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>ExtraÃ±o las cachemas con yucas ðŸ˜”</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label label_name  \\\n",
       "0  Nada como estar en lugares espectaculares, Man...      2   Positive   \n",
       "1    La policÃ­a anda pensando que eres un subversivo      1    Neutral   \n",
       "2  MAYRA GOÃ‘Y ...DEJALOS A TODOS EN PINDINGA!!! I...      0   Negative   \n",
       "3          Vamos a poner a un huevÃ³n mÃ¡s y nos vamos      0   Negative   \n",
       "4                   ExtraÃ±o las cachemas con yucas ðŸ˜”      1    Neutral   \n",
       "\n",
       "                                      tokenized_text  sent_token_length  \\\n",
       "0  Nada como estar en lugares espectaculares  Man...                 18   \n",
       "1    La policÃ­a anda pensando que eres un subversivo                  8   \n",
       "2  MAYRA GOÃ‘Y    DEJALOS A TODOS EN PINDINGA    I...                 10   \n",
       "3          Vamos a poner a un huevÃ³n mÃ¡s y nos vamos                 10   \n",
       "4                   ExtraÃ±o las cachemas con yucas ðŸ˜”                  6   \n",
       "\n",
       "   sent_bert_token_length  char_count  Character Count  \n",
       "0                      24         118              118  \n",
       "1                      10          47               47  \n",
       "2                      19          62               62  \n",
       "3                      11          41               41  \n",
       "4                       8          32               32  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = ds['train'].to_pandas()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7c0615c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode label and mapping label name\n",
    "#df[\"label\"] = df[\"label\"].apply(lambda x: label_encode(x))\n",
    "df[\"label_name\"] = df[\"label\"].apply(lambda x: label2name(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4c00ccd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean text, lowercase and remove punk\n",
    "#df[\"text\"] = df[\"text\"].apply(lambda x: remove_punct(clean(remove_emoji(x).lower())[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "05636464",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>label_name</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>sent_token_length</th>\n",
       "      <th>sent_bert_token_length</th>\n",
       "      <th>char_count</th>\n",
       "      <th>Character Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nada como estar en lugares espectaculares, Man...</td>\n",
       "      <td>2</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Nada como estar en lugares espectaculares  Man...</td>\n",
       "      <td>18</td>\n",
       "      <td>24</td>\n",
       "      <td>118</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>La policÃ­a anda pensando que eres un subversivo</td>\n",
       "      <td>1</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>La policÃ­a anda pensando que eres un subversivo</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>47</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MAYRA GOÃ‘Y ...DEJALOS A TODOS EN PINDINGA!!! I...</td>\n",
       "      <td>0</td>\n",
       "      <td>Negative</td>\n",
       "      <td>MAYRA GOÃ‘Y    DEJALOS A TODOS EN PINDINGA    I...</td>\n",
       "      <td>10</td>\n",
       "      <td>19</td>\n",
       "      <td>62</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Vamos a poner a un huevÃ³n mÃ¡s y nos vamos</td>\n",
       "      <td>0</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Vamos a poner a un huevÃ³n mÃ¡s y nos vamos</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ExtraÃ±o las cachemas con yucas ðŸ˜”</td>\n",
       "      <td>1</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>ExtraÃ±o las cachemas con yucas ðŸ˜”</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label label_name  \\\n",
       "0  Nada como estar en lugares espectaculares, Man...      2   Positive   \n",
       "1    La policÃ­a anda pensando que eres un subversivo      1    Neutral   \n",
       "2  MAYRA GOÃ‘Y ...DEJALOS A TODOS EN PINDINGA!!! I...      0   Negative   \n",
       "3          Vamos a poner a un huevÃ³n mÃ¡s y nos vamos      0   Negative   \n",
       "4                   ExtraÃ±o las cachemas con yucas ðŸ˜”      1    Neutral   \n",
       "\n",
       "                                      tokenized_text  sent_token_length  \\\n",
       "0  Nada como estar en lugares espectaculares  Man...                 18   \n",
       "1    La policÃ­a anda pensando que eres un subversivo                  8   \n",
       "2  MAYRA GOÃ‘Y    DEJALOS A TODOS EN PINDINGA    I...                 10   \n",
       "3          Vamos a poner a un huevÃ³n mÃ¡s y nos vamos                 10   \n",
       "4                   ExtraÃ±o las cachemas con yucas ðŸ˜”                  6   \n",
       "\n",
       "   sent_bert_token_length  char_count  Character Count  \n",
       "0                      24         118              118  \n",
       "1                      10          47               47  \n",
       "2                      19          62               62  \n",
       "3                      11          41               41  \n",
       "4                       8          32               32  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8299b318-0204-49cb-bf9a-14834e7796cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at pysentimiento/robertuito-base-uncased and are newly initialized: ['classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.bias', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "model_name = \"pysentimiento/robertuito-base-uncased\"\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=3\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.model_max_length = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "da7b8124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns = ['input_ids', 'attention_mask', 'label']\n",
    "# ds.set_format(type='torch', columns=columns)\n",
    "# ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae25e978",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8ed569d2-67ca-405d-aa88-3e6de71a2356",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pysentimiento.preprocessing import preprocess_tweet\n",
    "preprocessed_ds = ds.map(lambda ex: {\"text\": preprocess_tweet(ex[\"text\"], lang=\"es\")})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "99a78d85-4029-4621-b692-f63f396a2f6f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenized_ds = preprocessed_ds.map(\n",
    "    lambda batch: tokenizer(\n",
    "        batch[\"text\"], padding=True, truncation=True\n",
    "        ),\n",
    "    batched=True, batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1dd95bf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label', 'label_name', 'tokenized_text', 'sent_token_length', 'sent_bert_token_length', 'char_count', 'Character Count', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 9133\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label', 'label_name', 'tokenized_text', 'sent_token_length', 'sent_bert_token_length', 'char_count', 'Character Count', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 1128\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label', 'label_name', 'tokenized_text', 'sent_token_length', 'sent_bert_token_length', 'char_count', 'Character Count', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 1015\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d3634bf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 863, 4143, 1326, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_ds['train']['input_ids'][0][::10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7c23fbba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_ds['train']['attention_mask'][0][::10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f6d33cad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Nada como estar en lugares espectaculares, Manolito no me pierdo tus programas asi que pilas para nuevas aventurillas emoji cara feliz con ojos sonrientes emoji'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_ds['train']['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c88c53d1-0c5b-4b97-910a-75f6991d2d6f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install ipdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "469074ed-9e65-4a9e-913c-6151f5c5d8b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(30000, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(130, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import torch\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5d56e2f2-159e-4ffe-86fc-3659ed308b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer, DataCollatorWithPadding\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    per_device_train_batch_size=32,\n",
    "    output_dir=\"trainer_robertuito\",\n",
    "    warmup_ratio=0.1,\n",
    "    learning_rate=5e-5,\n",
    "    do_eval=True,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    num_train_epochs=5,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_ds[\"train\"],\n",
    "    eval_dataset=tokenized_ds[\"validation\"],\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6be1933a-b930-410d-91ff-646bdcb9a80f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6280988454818726, 'eval_f1': 0.7011731673470102, 'eval_recall': 0.7042052938005089, 'eval_runtime': 4.8757, 'eval_samples_per_second': 231.349, 'eval_steps_per_second': 28.919, 'epoch': 1.0}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/trainer.py:1591\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1589\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1590\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1591\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1592\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1593\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1594\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1595\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1596\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/trainer.py:1892\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1889\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   1891\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 1892\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1894\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1895\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   1896\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[1;32m   1897\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   1898\u001b[0m ):\n\u001b[1;32m   1899\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   1900\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/trainer.py:2787\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2785\u001b[0m         scaled_loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m   2786\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2787\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2789\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mdetach() \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mgradient_accumulation_steps\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/accelerate/accelerator.py:1923\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   1921\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler\u001b[38;5;241m.\u001b[39mscale(loss)\u001b[38;5;241m.\u001b[39mbackward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1922\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1923\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/robertuito-env/lib/python3.10/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/robertuito-env/lib/python3.10/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c407d3-9fa8-402c-85eb-7061a55c9984",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Test on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fec069",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate(tokenized_ds[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57814e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.load_state_dict(torch.load(f'./_BERT_epoch_3.model', map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4ae6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Error Analisys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b0f024-3661-4dcd-8dc5-8077e9db12a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46bbd55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = ds['validation'].to_pandas()\n",
    "#val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f23107",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737a62b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# step by step predictions on dataframe\n",
    "# We do this to view predictions in the pandas dataframe and easily filter them and perform error analysis.\n",
    "pred_final = []\n",
    "\n",
    "for i, row in tqdm(val_df.iterrows(), total=val_df.shape[0]):\n",
    "    predictions = []\n",
    "\n",
    "    text = row[\"text\"]\n",
    "    encoded_data_test_single = tokenizer.batch_encode_plus([text], \n",
    "    # add_special_tokens=config.add_special_tokens, \n",
    "    # return_attention_mask=config.return_attention_mask, \n",
    "    # pad_to_max_length=config.pad_to_max_length, \n",
    "    max_length=128,\n",
    "    # return_tensors=config.return_tensors\n",
    "    return_tensors=\"pt\"\n",
    "    )\n",
    "    input_ids_test = encoded_data_test_single['input_ids']\n",
    "    attention_masks_test = encoded_data_test_single['attention_mask']\n",
    "\n",
    "    \n",
    "    inputs = {'input_ids':      input_ids_test.to(device),\n",
    "              'attention_mask':attention_masks_test.to(device),\n",
    "             }\n",
    "\n",
    "    with torch.no_grad():        \n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    logits = outputs[0]\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    predictions.append(logits)\n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    pred_final.append(np.argmax(predictions, axis=1).flatten()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d5ea48-4899-4cb3-9027-0ea1cf46c0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add pred into val_df\n",
    "val_df[\"pred\"] = pred_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebc0161-59a5-4fc6-a34a-45f47f0416c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Add control column for easier wrong and right predictions\n",
    "control = val_df.pred.values == val_df.label.values\n",
    "val_df[\"control\"] = control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76106d47-0012-41ec-9656-9d3227934bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering false predictions\n",
    "val_df = val_df[val_df.control == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecdd05ba-780e-417f-a155-812850af1b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label to intent mapping\n",
    "name2label = {\"Negative\":0,\n",
    "              \"Neutral\":1,\n",
    "             \"Positive\":2\n",
    "             }\n",
    "label2name = {v: k for k, v in name2label.items()}\n",
    "\n",
    "val_df[\"pred_name\"] = val_df.pred.apply(lambda x: label2name.get(x)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e076559-81d8-4997-979e-330b1e15f200",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# We create a confusion matrix to better observe the classes that the model confuses.\n",
    "pred_name_values = val_df.pred_name.values\n",
    "label_values = val_df.label_name.values\n",
    "confmat = confusion_matrix(label_values, pred_name_values, labels=list(name2label.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86229af8-4484-4551-bfca-7280b8eab020",
   "metadata": {},
   "outputs": [],
   "source": [
    "confmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a282fc0e-f045-430b-9126-194627f8c043",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_confusion_val = pd.crosstab(label_values, pred_name_values)\n",
    "df_confusion_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6e4c35-1a05-44f2-8b40-a7a6dee7ae49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save confissuan matrix df\n",
    "df_confusion_val.to_csv(\"val_df_confusion.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab28ef2-630e-45b3-9552-ee2e42e66160",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c79614ce-e047-449c-b3a8-83ed2becfc20",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ce937d-9bfc-43c1-88a9-d99a4c7f56ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8f59ba-bb88-4992-ac2b-fbe58afe4158",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_data_test = tokenizer.batch_encode_plus(\n",
    "    val_df.text.values, \n",
    "    add_special_tokens=config.add_special_tokens, \n",
    "    return_attention_mask=config.return_attention_mask, \n",
    "    pad_to_max_length=config.pad_to_max_length,\n",
    "    max_length=128, \n",
    "    return_tensors=config.return_tensors\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6b284f-e6f6-4232-a1f0-15bda7fc19b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926977d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate the Model Qualitatively (Human Evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7faa99dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate the Model Quantitatively (with F1 Metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be445d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c839bdd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = val_df[0:20]['text']\n",
    "human_baseline_labels = val_df[0:20]['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebbb4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb03153f",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_baseline_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a070557c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#original_model_summaries = []\n",
    "model_classifications = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8436a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, text in enumerate(texts):\n",
    "    input_ids = tokenizer(text, return_tensors=\"pt\", max_length=128).input_ids.to('cuda')\n",
    "    logits = model(input_ids).logits\n",
    "    probabilities = logits.softmax(dim=-1).tolist()[0]\n",
    "    model_classifications.append(np.argmax(probabilities).flatten()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1a671b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_classifications"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

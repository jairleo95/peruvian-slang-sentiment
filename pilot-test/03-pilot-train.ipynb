{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de09e411",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-28 15:55:26.457510: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-28 15:55:26.492000: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-28 15:55:26.492027: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-28 15:55:26.493126: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-28 15:55:26.499252: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-28 15:55:27.113939: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import datasets\n",
    "import evaluate\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "import ipywidgets as widgets\n",
    "from transformers import TrainingArguments, Trainer, DataCollatorWithPadding\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "from pysentimiento.preprocessing import preprocess_tweet\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5af36065",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install torch==2.0.0\n",
    "#pip install pysentimiento==0.7.2\n",
    "#pip install evaluate==0.4.0\n",
    "#pip install datasets==2.14.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbffc10f-3389-44e6-b810-260a1d5415f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pysentimiento transformers datasets accelerate evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9604c3af-87e2-4977-9983-534dd7248e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://huggingface.co/docs/evaluate/base_evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50344bf0-03df-4017-b9ae-c37285b8825b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Three versions of RoBERTuito were\n",
    "#trained: a cased version which preserves the case found\n",
    "#in the original tweets, an uncased version, and a deacc\n",
    "#version, which lower-cases and removes accents on\n",
    "#tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a001ba7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ba02255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label to name\n",
    "def label2name(x):\n",
    "    if x == 0:\n",
    "        return \"Negative\"\n",
    "    if x == 1:\n",
    "        return \"Neutral\"\n",
    "    if x == 2:\n",
    "        return \"Positive\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d3164a0-faf4-4a4d-8a78-17b40b00c3f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "f1_metric = evaluate.load(\"f1\")\n",
    "recall_metric = evaluate.load(\"recall\")\n",
    "\n",
    "def compute_metrics (eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis = -1)\n",
    "    \n",
    "    results = {}\n",
    "    results.update(f1_metric.compute(predictions=preds, references = labels, average=\"macro\"))\n",
    "    results.update(recall_metric.compute(predictions=preds, references = labels, average=\"macro\"))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0bd8b7bc-ed54-4e65-ba9a-d2835b1abca8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90c97202-c5c6-484f-850a-46a9ee552251",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_files = {\"train\": \"data/train.csv\", \"validation\": \"data/val.csv\", \"test\": \"data/test.csv\"}\n",
    "ds = load_dataset(\"csv\", data_files=data_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8087bffe-c868-4323-90f0-4c6951f4fb5c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label', 'label_name', 'text_original', 'tokenized_text', 'sent_token_length', 'sent_bert_token_length', 'char_count', 'Character Count'],\n",
       "        num_rows: 7594\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label', 'label_name', 'text_original', 'tokenized_text', 'sent_token_length', 'sent_bert_token_length', 'char_count', 'Character Count'],\n",
       "        num_rows: 2374\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label', 'label_name', 'text_original', 'tokenized_text', 'sent_token_length', 'sent_bert_token_length', 'char_count', 'Character Count'],\n",
       "        num_rows: 1899\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3ca4ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#push to hugging face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "65695826-cdf5-4338-a815-15b7de7f4abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://huggingface.co/settings/tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "051a1e13-5030-4627-8a36-2326307dcf6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from huggingface_hub import notebook_login\n",
    "# notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "54b258b3-1cfc-4e6b-b7fa-fe02996400c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ds.push_to_hub(\"jairleo95/social-media-peruvian-sentiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e28595-3977-44f3-a9f0-9f62c1f3c802",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0c7abe81-d2ab-49c3-92bf-6c6e36d5d852",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': Value(dtype='string', id=None),\n",
       " 'label': Value(dtype='int64', id=None),\n",
       " 'label_name': Value(dtype='string', id=None),\n",
       " 'text_original': Value(dtype='string', id=None),\n",
       " 'tokenized_text': Value(dtype='string', id=None),\n",
       " 'sent_token_length': Value(dtype='int64', id=None),\n",
       " 'sent_bert_token_length': Value(dtype='int64', id=None),\n",
       " 'char_count': Value(dtype='int64', id=None),\n",
       " 'Character Count': Value(dtype='int64', id=None)}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[\"train\"].features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9a33842b-42eb-4966-8b48-f3dd7e1aeb33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 0, 0, 0, 2, 1, 0, 2, 2]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[\"test\"][\"label\"][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "68d24890",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>label_name</th>\n",
       "      <th>text_original</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>sent_token_length</th>\n",
       "      <th>sent_bert_token_length</th>\n",
       "      <th>char_count</th>\n",
       "      <th>Character Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>no yuli con eso se va con pendeivis 😞</td>\n",
       "      <td>1</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>No Yuli con eso se va con pendeivis 😞</td>\n",
       "      <td>no yuli con eso se va con pendeivis 😞</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>este es más bruto... cosas que necesita el  pe...</td>\n",
       "      <td>0</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Este es más bruto... Cosas que necesita el  Pe...</td>\n",
       "      <td>este es más bruto    cosas que necesita el  pe...</td>\n",
       "      <td>27</td>\n",
       "      <td>35</td>\n",
       "      <td>144</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bakan tu video pero el chambar es riko pero pa...</td>\n",
       "      <td>2</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Bakan tu video pero el chambar es riko pero pa...</td>\n",
       "      <td>bakan tu video pero el chambar es riko pero pa...</td>\n",
       "      <td>53</td>\n",
       "      <td>67</td>\n",
       "      <td>267</td>\n",
       "      <td>267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>no sabes que hacer para llamar la atención par...</td>\n",
       "      <td>0</td>\n",
       "      <td>Negative</td>\n",
       "      <td>no sabes que hacer para llamar la atención par...</td>\n",
       "      <td>no sabes que hacer para llamar la atención par...</td>\n",
       "      <td>18</td>\n",
       "      <td>20</td>\n",
       "      <td>93</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pe chino dame chamba mano, almenos pa limpiart...</td>\n",
       "      <td>1</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Pe CHINO DAME CHAMBA MANO, ALMENOS PA LIMPIART...</td>\n",
       "      <td>pe chino dame chamba mano  almenos pa limpiart...</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>61</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label label_name  \\\n",
       "0              no yuli con eso se va con pendeivis 😞      1    Neutral   \n",
       "1  este es más bruto... cosas que necesita el  pe...      0   Negative   \n",
       "2  bakan tu video pero el chambar es riko pero pa...      2   Positive   \n",
       "3  no sabes que hacer para llamar la atención par...      0   Negative   \n",
       "4  pe chino dame chamba mano, almenos pa limpiart...      1    Neutral   \n",
       "\n",
       "                                       text_original  \\\n",
       "0              No Yuli con eso se va con pendeivis 😞   \n",
       "1  Este es más bruto... Cosas que necesita el  Pe...   \n",
       "2  Bakan tu video pero el chambar es riko pero pa...   \n",
       "3  no sabes que hacer para llamar la atención par...   \n",
       "4  Pe CHINO DAME CHAMBA MANO, ALMENOS PA LIMPIART...   \n",
       "\n",
       "                                      tokenized_text  sent_token_length  \\\n",
       "0              no yuli con eso se va con pendeivis 😞                  9   \n",
       "1  este es más bruto    cosas que necesita el  pe...                 27   \n",
       "2  bakan tu video pero el chambar es riko pero pa...                 53   \n",
       "3  no sabes que hacer para llamar la atención par...                 18   \n",
       "4  pe chino dame chamba mano  almenos pa limpiart...                 11   \n",
       "\n",
       "   sent_bert_token_length  char_count  Character Count  \n",
       "0                      12          37               37  \n",
       "1                      35         144              144  \n",
       "2                      67         267              267  \n",
       "3                      20          93               93  \n",
       "4                      14          61               61  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = ds['train'].to_pandas()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7c0615c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode label and mapping label name\n",
    "#df[\"label\"] = df[\"label\"].apply(lambda x: label_encode(x))\n",
    "df[\"label_name\"] = df[\"label\"].apply(lambda x: label2name(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4c00ccd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean text, lowercase and remove punk\n",
    "#df[\"text\"] = df[\"text\"].apply(lambda x: remove_punct(clean(remove_emoji(x).lower())[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "05636464",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>label_name</th>\n",
       "      <th>text_original</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>sent_token_length</th>\n",
       "      <th>sent_bert_token_length</th>\n",
       "      <th>char_count</th>\n",
       "      <th>Character Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1633</th>\n",
       "      <td>eso sí es marketing señores   vayan a comprar ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Eso sí es marketing señores   Vayan a comprar ...</td>\n",
       "      <td>eso sí es marketing señores   vayan a comprar ...</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>maria pia copello  o haces el ridiculo estas h...</td>\n",
       "      <td>2</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Maria Pia Copello  o haces el ridiculo estas h...</td>\n",
       "      <td>maria pia copello  o haces el ridiculo estas h...</td>\n",
       "      <td>35</td>\n",
       "      <td>43</td>\n",
       "      <td>195</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3766</th>\n",
       "      <td>selena enriquez amor ya no vamos a esconder la...</td>\n",
       "      <td>1</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Selena Enriquez amor ya no vamos a esconder la...</td>\n",
       "      <td>selena enriquez amor ya no vamos a esconder la...</td>\n",
       "      <td>20</td>\n",
       "      <td>25</td>\n",
       "      <td>110</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1661</th>\n",
       "      <td>eres tu causa segundo emilio cabrera peña ?? 🤣🤣🤣</td>\n",
       "      <td>1</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Eres tu causa Segundo Emilio Cabrera Peña ?? 🤣🤣🤣🤣</td>\n",
       "      <td>eres tu causa segundo emilio cabrera peña    🤣🤣🤣</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5950</th>\n",
       "      <td>mis amigos son misios y tacaños carajo, pero t...</td>\n",
       "      <td>2</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Mis amigos son misios y tacaños carajo, pero T...</td>\n",
       "      <td>mis amigos son misios y tacaños carajo  pero t...</td>\n",
       "      <td>22</td>\n",
       "      <td>27</td>\n",
       "      <td>94</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5508</th>\n",
       "      <td>luis enrique rivas salazar no llega a la nota ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Luis Enrique Rivas Salazar no llega a la nota ...</td>\n",
       "      <td>luis enrique rivas salazar no llega a la nota ...</td>\n",
       "      <td>21</td>\n",
       "      <td>31</td>\n",
       "      <td>123</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>frank docha colazón no se por qué me acorde de...</td>\n",
       "      <td>1</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Frank Docha colazón No se por qué me acorde de...</td>\n",
       "      <td>frank docha colazón no se por qué me acorde de...</td>\n",
       "      <td>33</td>\n",
       "      <td>38</td>\n",
       "      <td>161</td>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5839</th>\n",
       "      <td>debe ser jodido trabajar en la bolsa</td>\n",
       "      <td>1</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Debe ser jodido trabajar en la bolsa</td>\n",
       "      <td>debe ser jodido trabajar en la bolsa</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>jaja así me sentí esa vez que se juntaron evel...</td>\n",
       "      <td>1</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Jajajaja Así me sentí esa vez que se juntaron ...</td>\n",
       "      <td>jaja así me sentí esa vez que se juntaron evel...</td>\n",
       "      <td>24</td>\n",
       "      <td>31</td>\n",
       "      <td>116</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6729</th>\n",
       "      <td>viva el. perú carajo 👍👍😁😁</td>\n",
       "      <td>2</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Viva el. Perú carajo 👍👍😁😁❤❤</td>\n",
       "      <td>viva el  perú carajo 👍👍😁😁</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label label_name  \\\n",
       "1633  eso sí es marketing señores   vayan a comprar ...      0   Negative   \n",
       "320   maria pia copello  o haces el ridiculo estas h...      2   Positive   \n",
       "3766  selena enriquez amor ya no vamos a esconder la...      1    Neutral   \n",
       "1661   eres tu causa segundo emilio cabrera peña ?? 🤣🤣🤣      1    Neutral   \n",
       "5950  mis amigos son misios y tacaños carajo, pero t...      2   Positive   \n",
       "5508  luis enrique rivas salazar no llega a la nota ...      1    Neutral   \n",
       "257   frank docha colazón no se por qué me acorde de...      1    Neutral   \n",
       "5839               debe ser jodido trabajar en la bolsa      1    Neutral   \n",
       "18    jaja así me sentí esa vez que se juntaron evel...      1    Neutral   \n",
       "6729                          viva el. perú carajo 👍👍😁😁      2   Positive   \n",
       "\n",
       "                                          text_original  \\\n",
       "1633  Eso sí es marketing señores   Vayan a comprar ...   \n",
       "320   Maria Pia Copello  o haces el ridiculo estas h...   \n",
       "3766  Selena Enriquez amor ya no vamos a esconder la...   \n",
       "1661  Eres tu causa Segundo Emilio Cabrera Peña ?? 🤣🤣🤣🤣   \n",
       "5950  Mis amigos son misios y tacaños carajo, pero T...   \n",
       "5508  Luis Enrique Rivas Salazar no llega a la nota ...   \n",
       "257   Frank Docha colazón No se por qué me acorde de...   \n",
       "5839               Debe ser jodido trabajar en la bolsa   \n",
       "18    Jajajaja Así me sentí esa vez que se juntaron ...   \n",
       "6729                        Viva el. Perú carajo 👍👍😁😁❤❤   \n",
       "\n",
       "                                         tokenized_text  sent_token_length  \\\n",
       "1633  eso sí es marketing señores   vayan a comprar ...                 11   \n",
       "320   maria pia copello  o haces el ridiculo estas h...                 35   \n",
       "3766  selena enriquez amor ya no vamos a esconder la...                 20   \n",
       "1661   eres tu causa segundo emilio cabrera peña    🤣🤣🤣                  9   \n",
       "5950  mis amigos son misios y tacaños carajo  pero t...                 22   \n",
       "5508  luis enrique rivas salazar no llega a la nota ...                 21   \n",
       "257   frank docha colazón no se por qué me acorde de...                 33   \n",
       "5839               debe ser jodido trabajar en la bolsa                  7   \n",
       "18    jaja así me sentí esa vez que se juntaron evel...                 24   \n",
       "6729                          viva el  perú carajo 👍👍😁😁                  5   \n",
       "\n",
       "      sent_bert_token_length  char_count  Character Count  \n",
       "1633                      14          60               60  \n",
       "320                       43         195              195  \n",
       "3766                      25         110              110  \n",
       "1661                       9          48               48  \n",
       "5950                      27          94               94  \n",
       "5508                      31         123              123  \n",
       "257                       38         161              161  \n",
       "5839                       7          36               36  \n",
       "18                        31         116              116  \n",
       "6729                       5          25               25  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8299b318-0204-49cb-bf9a-14834e7796cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "692278a6b1cd46518e931af3f48d2f58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/677 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "069b31c9ec994b5ca6f8fd5097e3701a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/435M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/darkstar/anaconda3/envs/robertuito-env/lib/python3.10/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "737a497563d5452cb9e8c73dc7ee4147",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/335 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e80b53e159db444caef2f5d2a9800dad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/859k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cdd76def03e4d6eb2359a01f3cb3f64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/150 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"pysentimiento/robertuito-base-deacc\"\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=3\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.model_max_length = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "da7b8124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns = ['input_ids', 'attention_mask', 'label']\n",
    "# ds.set_format(type='torch', columns=columns)\n",
    "# ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae25e978",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8ed569d2-67ca-405d-aa88-3e6de71a2356",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preprocessed_ds = ds.map(lambda ex: {\"text\": preprocess_tweet(ex[\"text\"], lang=\"es\")})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "99a78d85-4029-4621-b692-f63f396a2f6f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27101d68435e49f69007369ebc780455",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7594 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9edb7a4bb54a43be957590521dea0b21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2374 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01029991503b46e5bede26641823f5cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1899 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_ds = preprocessed_ds.map(\n",
    "    lambda batch: tokenizer(\n",
    "        batch[\"text\"], padding=True, truncation=True\n",
    "        ),\n",
    "    batched=True, batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1dd95bf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label', 'label_name', 'text_original', 'tokenized_text', 'sent_token_length', 'sent_bert_token_length', 'char_count', 'Character Count', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 7594\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label', 'label_name', 'text_original', 'tokenized_text', 'sent_token_length', 'sent_bert_token_length', 'char_count', 'Character Count', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 2374\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label', 'label_name', 'text_original', 'tokenized_text', 'sent_token_length', 'sent_bert_token_length', 'char_count', 'Character Count', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 1899\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d3634bf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 614, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_ds['train']['input_ids'][0][::10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7c23fbba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_ds['train']['attention_mask'][0][::10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f6d33cad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tu hermano gemelo manolo... sobrado la haces como su doble..   emoji cara con mano sobre la boca emoji  emoji cara con mano sobre la boca emoji'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_ds['train']['text'][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c88c53d1-0c5b-4b97-910a-75f6991d2d6f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install ipdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "469074ed-9e65-4a9e-913c-6151f5c5d8b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(30000, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(130, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import torch\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5d56e2f2-159e-4ffe-86fc-3659ed308b89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/darkstar/anaconda3/envs/robertuito-env/lib/python3.10/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    per_device_train_batch_size=32,\n",
    "    output_dir=\"robertuito_deacc/checkpoints\",\n",
    "    warmup_ratio=0.1,\n",
    "    learning_rate=5e-5,\n",
    "    do_eval=True,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    num_train_epochs=5,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_ds[\"train\"],\n",
    "    eval_dataset=tokenized_ds[\"validation\"],\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6be1933a-b930-410d-91ff-646bdcb9a80f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6313991546630859, 'eval_f1': 0.7198534892139952, 'eval_recall': 0.7223918970370447, 'eval_runtime': 12.5359, 'eval_samples_per_second': 189.377, 'eval_steps_per_second': 23.692, 'epoch': 1.0}\n",
      "{'eval_loss': 0.6540045738220215, 'eval_f1': 0.7314954208992441, 'eval_recall': 0.7329860853834665, 'eval_runtime': 11.2227, 'eval_samples_per_second': 211.535, 'eval_steps_per_second': 26.464, 'epoch': 2.0}\n",
      "{'loss': 0.5715, 'grad_norm': 2.7226808071136475, 'learning_rate': 3.221288515406163e-05, 'epoch': 2.1}\n",
      "{'eval_loss': 0.8846428394317627, 'eval_f1': 0.7200668848797278, 'eval_recall': 0.7196258639770946, 'eval_runtime': 11.404, 'eval_samples_per_second': 208.172, 'eval_steps_per_second': 26.043, 'epoch': 3.0}\n",
      "{'eval_loss': 1.145634412765503, 'eval_f1': 0.7269458376826164, 'eval_recall': 0.7266206827496301, 'eval_runtime': 11.4615, 'eval_samples_per_second': 207.129, 'eval_steps_per_second': 25.913, 'epoch': 4.0}\n",
      "{'loss': 0.1362, 'grad_norm': 0.27891427278518677, 'learning_rate': 8.870214752567695e-06, 'epoch': 4.2}\n",
      "{'eval_loss': 1.3200263977050781, 'eval_f1': 0.7235813135899516, 'eval_recall': 0.7247494518043839, 'eval_runtime': 12.8903, 'eval_samples_per_second': 184.169, 'eval_steps_per_second': 23.041, 'epoch': 5.0}\n",
      "{'train_runtime': 629.1552, 'train_samples_per_second': 60.351, 'train_steps_per_second': 1.891, 'train_loss': 0.3031648683948677, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1190, training_loss=0.3031648683948677, metrics={'train_runtime': 629.1552, 'train_samples_per_second': 60.351, 'train_steps_per_second': 1.891, 'train_loss': 0.3031648683948677, 'epoch': 5.0})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8925631b-f4c3-4cd5-9660-3fb18a4fc23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save trained model\n",
    "trainer.model.save_pretrained(\"robertuito_model/model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f2c407d3-9fa8-402c-85eb-7061a55c9984",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Test on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "34fec069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.2779923677444458, 'eval_f1': 0.7199614421342672, 'eval_recall': 0.720481119839072, 'eval_runtime': 10.146, 'eval_samples_per_second': 187.168, 'eval_steps_per_second': 23.458, 'epoch': 5.0}\n"
     ]
    }
   ],
   "source": [
    "evaluation_results = trainer.evaluate(tokenized_ds[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "12e4106c-224b-4651-9cdc-f89b6e5d15c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.2779923677444458,\n",
       " 'eval_f1': 0.7199614421342672,\n",
       " 'eval_recall': 0.720481119839072,\n",
       " 'eval_runtime': 10.146,\n",
       " 'eval_samples_per_second': 187.168,\n",
       " 'eval_steps_per_second': 23.458,\n",
       " 'epoch': 5.0}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7d9b0847-d809-4eeb-8b46-1a355b031930",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=array([[ 2.1242645 ,  1.1369343 , -3.8242478 ],\n",
       "       [-1.7109395 , -3.0079389 ,  4.684851  ],\n",
       "       [ 3.2433321 , -0.76485264, -2.360845  ],\n",
       "       ...,\n",
       "       [-2.5961633 , -3.2600904 ,  5.8412876 ],\n",
       "       [-3.290533  , -2.3925846 ,  5.176704  ],\n",
       "       [ 5.5061054 , -2.2806666 , -2.993916  ]], dtype=float32), label_ids=array([1, 0, 0, ..., 2, 1, 0]), metrics={'test_loss': 1.2779923677444458, 'test_f1': 0.7199614421342672, 'test_recall': 0.720481119839072, 'test_runtime': 10.1967, 'test_samples_per_second': 186.236, 'test_steps_per_second': 23.341})"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = trainer.predict(tokenized_ds[\"test\"])\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c42a8ab3-93da-4162-967b-792ace795c70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1899"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1775df1a-f613-4c97-afab-87b3870abd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels = tokenized_ds[\"test\"]['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "26982e5f-dc6f-4bd5-a799-cad8e1e4728c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1899"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a7087657-3e18-4ece-aa42-d96bea860046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.80164   0.84217   0.82141       811\n",
      "           1    0.61569   0.55435   0.58341       552\n",
      "           2    0.74545   0.76493   0.75506       536\n",
      "\n",
      "    accuracy                        0.73670      1899\n",
      "   macro avg    0.72093   0.72048   0.71996      1899\n",
      "weighted avg    0.73173   0.73670   0.73350      1899\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted_labels = [np.argmax(pred) for pred in predictions[0]]\n",
    "classification_rep = classification_report(true_labels, predicted_labels, digits=5)\n",
    "\n",
    "print(classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "57814e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.load_state_dict(torch.load(f'./_BERT_epoch_3.model', map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ed4ae6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Error Analisys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b0f024-3661-4dcd-8dc5-8077e9db12a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "46bbd55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = ds['validation'].to_pandas()\n",
    "#val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "737a62b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "918833cd06fc42678ce4d33c16007ae9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2374 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# step by step predictions on dataframe\n",
    "# We do this to view predictions in the pandas dataframe and easily filter them and perform error analysis.\n",
    "pred_final = []\n",
    "\n",
    "for i, row in tqdm(val_df.iterrows(), total=val_df.shape[0]):\n",
    "    predictions = []\n",
    "\n",
    "    text = row[\"text\"]\n",
    "    encoded_data_test_single = tokenizer.batch_encode_plus([text], \n",
    "    # add_special_tokens=config.add_special_tokens, \n",
    "    # return_attention_mask=config.return_attention_mask, \n",
    "    # pad_to_max_length=config.pad_to_max_length, \n",
    "    max_length=128,\n",
    "    # return_tensors=config.return_tensors\n",
    "    return_tensors=\"pt\"\n",
    "    )\n",
    "    input_ids_test = encoded_data_test_single['input_ids']\n",
    "    attention_masks_test = encoded_data_test_single['attention_mask']\n",
    "\n",
    "    \n",
    "    inputs = {'input_ids':      input_ids_test.to(device),\n",
    "              'attention_mask':attention_masks_test.to(device),\n",
    "             }\n",
    "\n",
    "    with torch.no_grad():        \n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    logits = outputs[0]\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    predictions.append(logits)\n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    pred_final.append(np.argmax(predictions, axis=1).flatten()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e2d5ea48-4899-4cb3-9027-0ea1cf46c0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add pred into val_df\n",
    "val_df[\"pred\"] = pred_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "aebc0161-59a5-4fc6-a34a-45f47f0416c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Add control column for easier wrong and right predictions\n",
    "control = val_df.pred.values == val_df.label.values\n",
    "val_df[\"control\"] = control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "76106d47-0012-41ec-9656-9d3227934bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering false predictions\n",
    "val_df = val_df[val_df.control == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ecdd05ba-780e-417f-a155-812850af1b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label to intent mapping\n",
    "name2label = {\"Negative\":0,\n",
    "              \"Neutral\":1,\n",
    "             \"Positive\":2\n",
    "             }\n",
    "label2name = {v: k for k, v in name2label.items()}\n",
    "\n",
    "val_df[\"pred_name\"] = val_df.pred.apply(lambda x: label2name.get(x)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0e076559-81d8-4997-979e-330b1e15f200",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# We create a confusion matrix to better observe the classes that the model confuses.\n",
    "pred_name_values = val_df.pred_name.values\n",
    "label_values = val_df.label_name.values\n",
    "confmat = confusion_matrix(label_values, pred_name_values, labels=list(name2label.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "86229af8-4484-4551-bfca-7280b8eab020",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0, 215,  38],\n",
       "       [128,   0, 137],\n",
       "       [ 50, 170,   0]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a282fc0e-f045-430b-9126-194627f8c043",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>Positive</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Negative</th>\n",
       "      <td>0</td>\n",
       "      <td>215</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neutral</th>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Positive</th>\n",
       "      <td>50</td>\n",
       "      <td>170</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0     Negative  Neutral  Positive\n",
       "row_0                                \n",
       "Negative         0      215        38\n",
       "Neutral        128        0       137\n",
       "Positive        50      170         0"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_confusion_val = pd.crosstab(label_values, pred_name_values)\n",
    "df_confusion_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8e6e4c35-1a05-44f2-8b40-a7a6dee7ae49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save confissuan matrix df\n",
    "df_confusion_val.to_csv(\"val_df_confusion.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab28ef2-630e-45b3-9552-ee2e42e66160",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c79614ce-e047-449c-b3a8-83ed2becfc20",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "04ce937d-9bfc-43c1-88a9-d99a4c7f56ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['no yuli con eso se va con pendeivis  emoji cara decepcionada emoji',\n",
       " 'este es más bruto... cosas que necesita el  perú obio que se importara.. todo lo que tienes que decir para que gané  kk.. mariposa  emoji mariposa emoji  gorda... !',\n",
       " 'bakan tu video pero el chambar es riko pero para puesto 1 no va ah, el caldo blanco es mucho mas sabroso, sin mencionar la infinidad de sopas, caldos y chupes q se prepara en arequipa como el chaque de tripas, el puchero o el timpo de rabos etc etc, saludos compare  emoji pulgar hacia arriba emoji',\n",
       " 'no sabes que hacer para llamar la atención para que te dean bola en tus canciones copiada  emoji cara vomitando emoji  emoji cara vomitando emoji  emoji cara vomitando emoji',\n",
       " 'pe chino dame chamba mano, almenos pa limpiarte las tabas :v emoji cara de por favor emoji',\n",
       " 'casaca de cuero?? cómo abran sudado esas alicias  emoji cara revolviéndose de la risa emoji  emoji cara revolviéndose de la risa emoji  emoji cara revolviéndose de la risa emoji',\n",
       " 'marcela jurado ramos ya kisieras llegarle a ala mugre de las pezuñas tu a maria pia copello  emoji cara llorando de risa emoji  emoji cara llorando de risa emoji  emoji cara revolviéndose de la risa emoji',\n",
       " 'jajja su aparato!!!  emoji cara revolviéndose de la risa emoji',\n",
       " '🤷\\u200d no les hagas caso, solo son envidiosos porque ellos seguro no conocen otro idioma que el español; yo sé que si lo hablas  emoji pulgar hacia arriba emoji . veo mucho animé japonés  emoji cara radiante con ojos sonrientes emoji . yo hablo francés, alemán y español y me vale verga la gente envidiosa que no acepta los conocimientos de los demás.  emoji cara guiñando el ojo emoji  ánimo y sigue con tus lecciones, a mi me encanta tu blog.',\n",
       " 'el valiente que recibió un millón de cocos para fallar a favor de la impugnación de las ratas que apoyas ridículo, pedo...  emoji cara revolviéndose de la risa emoji  emoji cara revolviéndose de la risa emoji  emoji cara revolviéndose de la risa emoji',\n",
       " 'tu hermano gemelo manolo... sobrado la haces como su doble..   emoji cara con mano sobre la boca emoji  emoji cara con mano sobre la boca emoji',\n",
       " 'hablando huevadas de huevones jaja  emoji cara revolviéndose de la risa emoji',\n",
       " 'los únicos babosos serán los que sigan viendo tu programa... emoji cara llorando de risa emoji',\n",
       " 'tan bella esa carita de la japeruana mamacita... emoji cara sonriendo con ojos de corazón emoji',\n",
       " 'emoji cara de payaso emoji  emoji cara de payaso emoji  emoji cara de payaso emoji  nunca fuistes arquero mantequilla',\n",
       " 'con tanta nececidad que salen de su país.y no entiendo porqué esa maldad con las personas que no tiene culpa de su desgracia..esa  ira. ..entre todos  la pueden utilizar contra su presidente maduro..a ese es que le tienen que cobrar. lo malo que les pasa emoji cara cabreada emoji',\n",
       " 'angello ormaeche chris ormaeche ruiz miguel mejia que suba el chamo  emoji cara revolviéndose de la risa emoji',\n",
       " 'los pallares verdes son lo mejor del mundo!!  emoji cara feliz con ojos sonrientes emoji',\n",
       " 'jaja así me sentí esa vez que se juntaron evelyn leidy y tu amiga vane... y yo tratando de tomar mi sopita de pollo emoji cara llorando emoji',\n",
       " 'ay querido gaston trajiste a mi mente quizas unos de los mas gratos recuerdos de mi niñez e incluso juventud el chifa! los uribe somos de ancestro serrano pero nos encanta el chifa! creo q todo inicia con mi abuelo pedro uribe en palpa hacienda al norte chico...el llevaba o hacia chifa en casa, mis padres nos llevaron a nosotros también en huaral o chancay a los mismos chifas esos que dices de las cortinas...y luego yo he llevado a mi esposo y mi hijo a lo mismo ( se tambien que a  todos mis primos les encanta el chifa) y ahora aun en eeuu mi hijo de 16 años el único plato que sabe preparar y le sale deli porque le he enseñado como tu dices a saltear es el chaufa! bendito tu peruano de altura que nos regalas estos momentos de enorme añoranza y alegria!!! pd: y ya te he dicho si no cocinas escribe!!!...si bien la cocina peruana gano a su mejor embajador...estoy segura que la literatura peruana esta un poco resentida! emoji cara con mano sobre la boca emoji',\n",
       " 'dejen gobernar carj!!! solo defienden los intereses de los grupo de poder económico acostumbrados a manejar al perú como su chacra emoji cara con símbolos en la boca emoji  emoji cara con símbolos en la boca emoji  emoji cara con símbolos en la boca emoji',\n",
       " 'tienes un estilo único bro yo fui con mi hijo x hay x camana y pucha ve tantas cosas clásicas y le gusta saludos  emoji cara sonriendo ligeramente emoji',\n",
       " 'https://url/  siga su propio consejo señor ortiz. deje de ser una vieja avinagrada, que esta en el balcón, viendo quien le saca la vuelta a quien, para tirar dedo, para chismear, para generar la intriga, la maledicencia, el veneno, no pues  emoji cara sonriendo con sudor frío emoji  no seas como una de esas viejas chismosas, no vale la pena.   sea congruente señor ortiz  emoji cara con mano sobre la boca emoji',\n",
       " 'pa concha, escritor quieres ser¿escritor de qué?',\n",
       " 'a poco escuchóse el rumor de bestias al galope',\n",
       " 'amaría amaría amaría viajar junto con mi mejor amiga al norte, después de tanto estrés de los finales de la u siento que nos merecemos un viajecito para relajar y de paso chapar un poquito de sol que estamos maaas blancas  emoji cara con ojos en blanco emoji  emoji cara con ojos en blanco emoji  emoji cara con ojos en blanco emoji',\n",
       " 'cómo diría mi brother iván: sarta de ensaladas  emoji cara revolviéndose de la risa emoji !',\n",
       " 'adharaalmora cuando nos juntamos a rajar  emoji cara llorando de risa emoji',\n",
       " 'jj note iguales ni alas pezuñas de  magali emoji cara revolviéndose de la risa emoji  emoji cara revolviéndose de la risa emoji  emoji cara revolviéndose de la risa emoji  esta con ganas de facturar',\n",
       " 'estoy esperando los dichosos audios bomba  y nada ya me cansé de esperar tanto les duele que un serrano sea tu presidente acostumbrate pedro castillo terrones es el presidente del pueblo peruano arriva perú  emoji bandera perú emoji  emoji bandera perú emoji  emoji pulgar hacia arriba emoji  emoji pulgar hacia arriba emoji  emoji pulgar hacia arriba emoji']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_ds['train']['text'][:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6c8f59ba-bb88-4992-ac2b-fbe58afe4158",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'config' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m encoded_data_test \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mbatch_encode_plus(\n\u001b[1;32m      2\u001b[0m     val_df\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39mvalues, \n\u001b[0;32m----> 3\u001b[0m     add_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[43mconfig\u001b[49m\u001b[38;5;241m.\u001b[39madd_special_tokens, \n\u001b[1;32m      4\u001b[0m     return_attention_mask\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mreturn_attention_mask, \n\u001b[1;32m      5\u001b[0m     pad_to_max_length\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpad_to_max_length,\n\u001b[1;32m      6\u001b[0m     max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m, \n\u001b[1;32m      7\u001b[0m     return_tensors\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mreturn_tensors\n\u001b[1;32m      8\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'config' is not defined"
     ]
    }
   ],
   "source": [
    "encoded_data_test = tokenizer.batch_encode_plus(\n",
    "    val_df.text.values, \n",
    "    add_special_tokens=config.add_special_tokens, \n",
    "    return_attention_mask=config.return_attention_mask, \n",
    "    pad_to_max_length=config.pad_to_max_length,\n",
    "    max_length=128, \n",
    "    return_tensors=config.return_tensors\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6b284f-e6f6-4232-a1f0-15bda7fc19b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926977d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate the Model Qualitatively (Human Evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7faa99dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate the Model Quantitatively (with F1 Metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be445d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c839bdd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = val_df[0:20]['text']\n",
    "human_baseline_labels = val_df[0:20]['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebbb4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb03153f",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_baseline_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a070557c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#original_model_summaries = []\n",
    "model_classifications = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8436a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, text in enumerate(texts):\n",
    "    input_ids = tokenizer(text, return_tensors=\"pt\", max_length=128).input_ids.to('cuda')\n",
    "    logits = model(input_ids).logits\n",
    "    probabilities = logits.softmax(dim=-1).tolist()[0]\n",
    "    model_classifications.append(np.argmax(probabilities).flatten()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1a671b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_classifications"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

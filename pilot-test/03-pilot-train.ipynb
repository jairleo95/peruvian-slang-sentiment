{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de09e411",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-28 15:55:26.457510: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-03-28 15:55:26.492000: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-28 15:55:26.492027: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-28 15:55:26.493126: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-28 15:55:26.499252: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-28 15:55:27.113939: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import datasets\n",
    "import evaluate\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "import ipywidgets as widgets\n",
    "from transformers import TrainingArguments, Trainer, DataCollatorWithPadding\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "from pysentimiento.preprocessing import preprocess_tweet\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5af36065",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install torch==2.0.0\n",
    "#pip install pysentimiento==0.7.2\n",
    "#pip install evaluate==0.4.0\n",
    "#pip install datasets==2.14.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbffc10f-3389-44e6-b810-260a1d5415f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pysentimiento transformers datasets accelerate evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9604c3af-87e2-4977-9983-534dd7248e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://huggingface.co/docs/evaluate/base_evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50344bf0-03df-4017-b9ae-c37285b8825b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Three versions of RoBERTuito were\n",
    "#trained: a cased version which preserves the case found\n",
    "#in the original tweets, an uncased version, and a deacc\n",
    "#version, which lower-cases and removes accents on\n",
    "#tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a001ba7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ba02255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label to name\n",
    "def label2name(x):\n",
    "    if x == 0:\n",
    "        return \"Negative\"\n",
    "    if x == 1:\n",
    "        return \"Neutral\"\n",
    "    if x == 2:\n",
    "        return \"Positive\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d3164a0-faf4-4a4d-8a78-17b40b00c3f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "f1_metric = evaluate.load(\"f1\")\n",
    "recall_metric = evaluate.load(\"recall\")\n",
    "\n",
    "def compute_metrics (eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis = -1)\n",
    "    \n",
    "    results = {}\n",
    "    results.update(f1_metric.compute(predictions=preds, references = labels, average=\"macro\"))\n",
    "    results.update(recall_metric.compute(predictions=preds, references = labels, average=\"macro\"))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0bd8b7bc-ed54-4e65-ba9a-d2835b1abca8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90c97202-c5c6-484f-850a-46a9ee552251",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_files = {\"train\": \"data/train.csv\", \"validation\": \"data/val.csv\", \"test\": \"data/test.csv\"}\n",
    "ds = load_dataset(\"csv\", data_files=data_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8087bffe-c868-4323-90f0-4c6951f4fb5c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label', 'label_name', 'text_original', 'tokenized_text', 'sent_token_length', 'sent_bert_token_length', 'char_count', 'Character Count'],\n",
       "        num_rows: 7594\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label', 'label_name', 'text_original', 'tokenized_text', 'sent_token_length', 'sent_bert_token_length', 'char_count', 'Character Count'],\n",
       "        num_rows: 2374\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label', 'label_name', 'text_original', 'tokenized_text', 'sent_token_length', 'sent_bert_token_length', 'char_count', 'Character Count'],\n",
       "        num_rows: 1899\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3ca4ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#push to hugging face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "65695826-cdf5-4338-a815-15b7de7f4abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://huggingface.co/settings/tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "051a1e13-5030-4627-8a36-2326307dcf6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from huggingface_hub import notebook_login\n",
    "# notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "54b258b3-1cfc-4e6b-b7fa-fe02996400c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ds.push_to_hub(\"jairleo95/social-media-peruvian-sentiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e28595-3977-44f3-a9f0-9f62c1f3c802",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0c7abe81-d2ab-49c3-92bf-6c6e36d5d852",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': Value(dtype='string', id=None),\n",
       " 'label': Value(dtype='int64', id=None),\n",
       " 'label_name': Value(dtype='string', id=None),\n",
       " 'text_original': Value(dtype='string', id=None),\n",
       " 'tokenized_text': Value(dtype='string', id=None),\n",
       " 'sent_token_length': Value(dtype='int64', id=None),\n",
       " 'sent_bert_token_length': Value(dtype='int64', id=None),\n",
       " 'char_count': Value(dtype='int64', id=None),\n",
       " 'Character Count': Value(dtype='int64', id=None)}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[\"train\"].features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9a33842b-42eb-4966-8b48-f3dd7e1aeb33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 0, 0, 0, 2, 1, 0, 2, 2]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[\"test\"][\"label\"][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "68d24890",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>label_name</th>\n",
       "      <th>text_original</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>sent_token_length</th>\n",
       "      <th>sent_bert_token_length</th>\n",
       "      <th>char_count</th>\n",
       "      <th>Character Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>no yuli con eso se va con pendeivis 游</td>\n",
       "      <td>1</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>No Yuli con eso se va con pendeivis 游</td>\n",
       "      <td>no yuli con eso se va con pendeivis 游</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>37</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>este es m치s bruto... cosas que necesita el  pe...</td>\n",
       "      <td>0</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Este es m치s bruto... Cosas que necesita el  Pe...</td>\n",
       "      <td>este es m치s bruto    cosas que necesita el  pe...</td>\n",
       "      <td>27</td>\n",
       "      <td>35</td>\n",
       "      <td>144</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bakan tu video pero el chambar es riko pero pa...</td>\n",
       "      <td>2</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Bakan tu video pero el chambar es riko pero pa...</td>\n",
       "      <td>bakan tu video pero el chambar es riko pero pa...</td>\n",
       "      <td>53</td>\n",
       "      <td>67</td>\n",
       "      <td>267</td>\n",
       "      <td>267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>no sabes que hacer para llamar la atenci칩n par...</td>\n",
       "      <td>0</td>\n",
       "      <td>Negative</td>\n",
       "      <td>no sabes que hacer para llamar la atenci칩n par...</td>\n",
       "      <td>no sabes que hacer para llamar la atenci칩n par...</td>\n",
       "      <td>18</td>\n",
       "      <td>20</td>\n",
       "      <td>93</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pe chino dame chamba mano, almenos pa limpiart...</td>\n",
       "      <td>1</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Pe CHINO DAME CHAMBA MANO, ALMENOS PA LIMPIART...</td>\n",
       "      <td>pe chino dame chamba mano  almenos pa limpiart...</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>61</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label label_name  \\\n",
       "0              no yuli con eso se va con pendeivis 游      1    Neutral   \n",
       "1  este es m치s bruto... cosas que necesita el  pe...      0   Negative   \n",
       "2  bakan tu video pero el chambar es riko pero pa...      2   Positive   \n",
       "3  no sabes que hacer para llamar la atenci칩n par...      0   Negative   \n",
       "4  pe chino dame chamba mano, almenos pa limpiart...      1    Neutral   \n",
       "\n",
       "                                       text_original  \\\n",
       "0              No Yuli con eso se va con pendeivis 游   \n",
       "1  Este es m치s bruto... Cosas que necesita el  Pe...   \n",
       "2  Bakan tu video pero el chambar es riko pero pa...   \n",
       "3  no sabes que hacer para llamar la atenci칩n par...   \n",
       "4  Pe CHINO DAME CHAMBA MANO, ALMENOS PA LIMPIART...   \n",
       "\n",
       "                                      tokenized_text  sent_token_length  \\\n",
       "0              no yuli con eso se va con pendeivis 游                  9   \n",
       "1  este es m치s bruto    cosas que necesita el  pe...                 27   \n",
       "2  bakan tu video pero el chambar es riko pero pa...                 53   \n",
       "3  no sabes que hacer para llamar la atenci칩n par...                 18   \n",
       "4  pe chino dame chamba mano  almenos pa limpiart...                 11   \n",
       "\n",
       "   sent_bert_token_length  char_count  Character Count  \n",
       "0                      12          37               37  \n",
       "1                      35         144              144  \n",
       "2                      67         267              267  \n",
       "3                      20          93               93  \n",
       "4                      14          61               61  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = ds['train'].to_pandas()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7c0615c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode label and mapping label name\n",
    "#df[\"label\"] = df[\"label\"].apply(lambda x: label_encode(x))\n",
    "df[\"label_name\"] = df[\"label\"].apply(lambda x: label2name(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4c00ccd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean text, lowercase and remove punk\n",
    "#df[\"text\"] = df[\"text\"].apply(lambda x: remove_punct(clean(remove_emoji(x).lower())[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "05636464",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>label_name</th>\n",
       "      <th>text_original</th>\n",
       "      <th>tokenized_text</th>\n",
       "      <th>sent_token_length</th>\n",
       "      <th>sent_bert_token_length</th>\n",
       "      <th>char_count</th>\n",
       "      <th>Character Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1633</th>\n",
       "      <td>eso s칤 es marketing se침ores   vayan a comprar ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Eso s칤 es marketing se침ores   Vayan a comprar ...</td>\n",
       "      <td>eso s칤 es marketing se침ores   vayan a comprar ...</td>\n",
       "      <td>11</td>\n",
       "      <td>14</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>maria pia copello  o haces el ridiculo estas h...</td>\n",
       "      <td>2</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Maria Pia Copello  o haces el ridiculo estas h...</td>\n",
       "      <td>maria pia copello  o haces el ridiculo estas h...</td>\n",
       "      <td>35</td>\n",
       "      <td>43</td>\n",
       "      <td>195</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3766</th>\n",
       "      <td>selena enriquez amor ya no vamos a esconder la...</td>\n",
       "      <td>1</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Selena Enriquez amor ya no vamos a esconder la...</td>\n",
       "      <td>selena enriquez amor ya no vamos a esconder la...</td>\n",
       "      <td>20</td>\n",
       "      <td>25</td>\n",
       "      <td>110</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1661</th>\n",
       "      <td>eres tu causa segundo emilio cabrera pe침a ?? 游뱎游뱎游뱎</td>\n",
       "      <td>1</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Eres tu causa Segundo Emilio Cabrera Pe침a ?? 游뱎游뱎游뱎游뱎</td>\n",
       "      <td>eres tu causa segundo emilio cabrera pe침a    游뱎游뱎游뱎</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>48</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5950</th>\n",
       "      <td>mis amigos son misios y taca침os carajo, pero t...</td>\n",
       "      <td>2</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Mis amigos son misios y taca침os carajo, pero T...</td>\n",
       "      <td>mis amigos son misios y taca침os carajo  pero t...</td>\n",
       "      <td>22</td>\n",
       "      <td>27</td>\n",
       "      <td>94</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5508</th>\n",
       "      <td>luis enrique rivas salazar no llega a la nota ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Luis Enrique Rivas Salazar no llega a la nota ...</td>\n",
       "      <td>luis enrique rivas salazar no llega a la nota ...</td>\n",
       "      <td>21</td>\n",
       "      <td>31</td>\n",
       "      <td>123</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>frank docha colaz칩n no se por qu칠 me acorde de...</td>\n",
       "      <td>1</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Frank Docha colaz칩n No se por qu칠 me acorde de...</td>\n",
       "      <td>frank docha colaz칩n no se por qu칠 me acorde de...</td>\n",
       "      <td>33</td>\n",
       "      <td>38</td>\n",
       "      <td>161</td>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5839</th>\n",
       "      <td>debe ser jodido trabajar en la bolsa</td>\n",
       "      <td>1</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Debe ser jodido trabajar en la bolsa</td>\n",
       "      <td>debe ser jodido trabajar en la bolsa</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>jaja as칤 me sent칤 esa vez que se juntaron evel...</td>\n",
       "      <td>1</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Jajajaja As칤 me sent칤 esa vez que se juntaron ...</td>\n",
       "      <td>jaja as칤 me sent칤 esa vez que se juntaron evel...</td>\n",
       "      <td>24</td>\n",
       "      <td>31</td>\n",
       "      <td>116</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6729</th>\n",
       "      <td>viva el. per칰 carajo 游녨游녨游때游때</td>\n",
       "      <td>2</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Viva el. Per칰 carajo 游녨游녨游때游때仇벅롟</td>\n",
       "      <td>viva el  per칰 carajo 游녨游녨游때游때</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label label_name  \\\n",
       "1633  eso s칤 es marketing se침ores   vayan a comprar ...      0   Negative   \n",
       "320   maria pia copello  o haces el ridiculo estas h...      2   Positive   \n",
       "3766  selena enriquez amor ya no vamos a esconder la...      1    Neutral   \n",
       "1661   eres tu causa segundo emilio cabrera pe침a ?? 游뱎游뱎游뱎      1    Neutral   \n",
       "5950  mis amigos son misios y taca침os carajo, pero t...      2   Positive   \n",
       "5508  luis enrique rivas salazar no llega a la nota ...      1    Neutral   \n",
       "257   frank docha colaz칩n no se por qu칠 me acorde de...      1    Neutral   \n",
       "5839               debe ser jodido trabajar en la bolsa      1    Neutral   \n",
       "18    jaja as칤 me sent칤 esa vez que se juntaron evel...      1    Neutral   \n",
       "6729                          viva el. per칰 carajo 游녨游녨游때游때      2   Positive   \n",
       "\n",
       "                                          text_original  \\\n",
       "1633  Eso s칤 es marketing se침ores   Vayan a comprar ...   \n",
       "320   Maria Pia Copello  o haces el ridiculo estas h...   \n",
       "3766  Selena Enriquez amor ya no vamos a esconder la...   \n",
       "1661  Eres tu causa Segundo Emilio Cabrera Pe침a ?? 游뱎游뱎游뱎游뱎   \n",
       "5950  Mis amigos son misios y taca침os carajo, pero T...   \n",
       "5508  Luis Enrique Rivas Salazar no llega a la nota ...   \n",
       "257   Frank Docha colaz칩n No se por qu칠 me acorde de...   \n",
       "5839               Debe ser jodido trabajar en la bolsa   \n",
       "18    Jajajaja As칤 me sent칤 esa vez que se juntaron ...   \n",
       "6729                        Viva el. Per칰 carajo 游녨游녨游때游때仇벅롟   \n",
       "\n",
       "                                         tokenized_text  sent_token_length  \\\n",
       "1633  eso s칤 es marketing se침ores   vayan a comprar ...                 11   \n",
       "320   maria pia copello  o haces el ridiculo estas h...                 35   \n",
       "3766  selena enriquez amor ya no vamos a esconder la...                 20   \n",
       "1661   eres tu causa segundo emilio cabrera pe침a    游뱎游뱎游뱎                  9   \n",
       "5950  mis amigos son misios y taca침os carajo  pero t...                 22   \n",
       "5508  luis enrique rivas salazar no llega a la nota ...                 21   \n",
       "257   frank docha colaz칩n no se por qu칠 me acorde de...                 33   \n",
       "5839               debe ser jodido trabajar en la bolsa                  7   \n",
       "18    jaja as칤 me sent칤 esa vez que se juntaron evel...                 24   \n",
       "6729                          viva el  per칰 carajo 游녨游녨游때游때                  5   \n",
       "\n",
       "      sent_bert_token_length  char_count  Character Count  \n",
       "1633                      14          60               60  \n",
       "320                       43         195              195  \n",
       "3766                      25         110              110  \n",
       "1661                       9          48               48  \n",
       "5950                      27          94               94  \n",
       "5508                      31         123              123  \n",
       "257                       38         161              161  \n",
       "5839                       7          36               36  \n",
       "18                        31         116              116  \n",
       "6729                       5          25               25  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8299b318-0204-49cb-bf9a-14834e7796cb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "692278a6b1cd46518e931af3f48d2f58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/677 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "069b31c9ec994b5ca6f8fd5097e3701a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/435M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/darkstar/anaconda3/envs/robertuito-env/lib/python3.10/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "737a497563d5452cb9e8c73dc7ee4147",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/335 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e80b53e159db444caef2f5d2a9800dad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/859k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cdd76def03e4d6eb2359a01f3cb3f64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/150 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"pysentimiento/robertuito-base-deacc\"\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=3\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.model_max_length = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "da7b8124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns = ['input_ids', 'attention_mask', 'label']\n",
    "# ds.set_format(type='torch', columns=columns)\n",
    "# ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae25e978",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8ed569d2-67ca-405d-aa88-3e6de71a2356",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "preprocessed_ds = ds.map(lambda ex: {\"text\": preprocess_tweet(ex[\"text\"], lang=\"es\")})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "99a78d85-4029-4621-b692-f63f396a2f6f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27101d68435e49f69007369ebc780455",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7594 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9edb7a4bb54a43be957590521dea0b21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2374 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01029991503b46e5bede26641823f5cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1899 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_ds = preprocessed_ds.map(\n",
    "    lambda batch: tokenizer(\n",
    "        batch[\"text\"], padding=True, truncation=True\n",
    "        ),\n",
    "    batched=True, batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1dd95bf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label', 'label_name', 'text_original', 'tokenized_text', 'sent_token_length', 'sent_bert_token_length', 'char_count', 'Character Count', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 7594\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label', 'label_name', 'text_original', 'tokenized_text', 'sent_token_length', 'sent_bert_token_length', 'char_count', 'Character Count', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 2374\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label', 'label_name', 'text_original', 'tokenized_text', 'sent_token_length', 'sent_bert_token_length', 'char_count', 'Character Count', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 1899\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d3634bf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 614, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_ds['train']['input_ids'][0][::10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7c23fbba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_ds['train']['attention_mask'][0][::10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f6d33cad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tu hermano gemelo manolo... sobrado la haces como su doble..   emoji cara con mano sobre la boca emoji  emoji cara con mano sobre la boca emoji'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_ds['train']['text'][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c88c53d1-0c5b-4b97-910a-75f6991d2d6f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install ipdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "469074ed-9e65-4a9e-913c-6151f5c5d8b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(30000, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(130, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import torch\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5d56e2f2-159e-4ffe-86fc-3659ed308b89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/darkstar/anaconda3/envs/robertuito-env/lib/python3.10/site-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
      "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    per_device_train_batch_size=32,\n",
    "    output_dir=\"robertuito_deacc/checkpoints\",\n",
    "    warmup_ratio=0.1,\n",
    "    learning_rate=5e-5,\n",
    "    do_eval=True,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    num_train_epochs=5,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_ds[\"train\"],\n",
    "    eval_dataset=tokenized_ds[\"validation\"],\n",
    "    compute_metrics=compute_metrics,\n",
    "    data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6be1933a-b930-410d-91ff-646bdcb9a80f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6313991546630859, 'eval_f1': 0.7198534892139952, 'eval_recall': 0.7223918970370447, 'eval_runtime': 12.5359, 'eval_samples_per_second': 189.377, 'eval_steps_per_second': 23.692, 'epoch': 1.0}\n",
      "{'eval_loss': 0.6540045738220215, 'eval_f1': 0.7314954208992441, 'eval_recall': 0.7329860853834665, 'eval_runtime': 11.2227, 'eval_samples_per_second': 211.535, 'eval_steps_per_second': 26.464, 'epoch': 2.0}\n",
      "{'loss': 0.5715, 'grad_norm': 2.7226808071136475, 'learning_rate': 3.221288515406163e-05, 'epoch': 2.1}\n",
      "{'eval_loss': 0.8846428394317627, 'eval_f1': 0.7200668848797278, 'eval_recall': 0.7196258639770946, 'eval_runtime': 11.404, 'eval_samples_per_second': 208.172, 'eval_steps_per_second': 26.043, 'epoch': 3.0}\n",
      "{'eval_loss': 1.145634412765503, 'eval_f1': 0.7269458376826164, 'eval_recall': 0.7266206827496301, 'eval_runtime': 11.4615, 'eval_samples_per_second': 207.129, 'eval_steps_per_second': 25.913, 'epoch': 4.0}\n",
      "{'loss': 0.1362, 'grad_norm': 0.27891427278518677, 'learning_rate': 8.870214752567695e-06, 'epoch': 4.2}\n",
      "{'eval_loss': 1.3200263977050781, 'eval_f1': 0.7235813135899516, 'eval_recall': 0.7247494518043839, 'eval_runtime': 12.8903, 'eval_samples_per_second': 184.169, 'eval_steps_per_second': 23.041, 'epoch': 5.0}\n",
      "{'train_runtime': 629.1552, 'train_samples_per_second': 60.351, 'train_steps_per_second': 1.891, 'train_loss': 0.3031648683948677, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1190, training_loss=0.3031648683948677, metrics={'train_runtime': 629.1552, 'train_samples_per_second': 60.351, 'train_steps_per_second': 1.891, 'train_loss': 0.3031648683948677, 'epoch': 5.0})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8925631b-f4c3-4cd5-9660-3fb18a4fc23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save trained model\n",
    "trainer.model.save_pretrained(\"robertuito_model/model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f2c407d3-9fa8-402c-85eb-7061a55c9984",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Test on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "34fec069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.2779923677444458, 'eval_f1': 0.7199614421342672, 'eval_recall': 0.720481119839072, 'eval_runtime': 10.146, 'eval_samples_per_second': 187.168, 'eval_steps_per_second': 23.458, 'epoch': 5.0}\n"
     ]
    }
   ],
   "source": [
    "evaluation_results = trainer.evaluate(tokenized_ds[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "12e4106c-224b-4651-9cdc-f89b6e5d15c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.2779923677444458,\n",
       " 'eval_f1': 0.7199614421342672,\n",
       " 'eval_recall': 0.720481119839072,\n",
       " 'eval_runtime': 10.146,\n",
       " 'eval_samples_per_second': 187.168,\n",
       " 'eval_steps_per_second': 23.458,\n",
       " 'epoch': 5.0}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7d9b0847-d809-4eeb-8b46-1a355b031930",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PredictionOutput(predictions=array([[ 2.1242645 ,  1.1369343 , -3.8242478 ],\n",
       "       [-1.7109395 , -3.0079389 ,  4.684851  ],\n",
       "       [ 3.2433321 , -0.76485264, -2.360845  ],\n",
       "       ...,\n",
       "       [-2.5961633 , -3.2600904 ,  5.8412876 ],\n",
       "       [-3.290533  , -2.3925846 ,  5.176704  ],\n",
       "       [ 5.5061054 , -2.2806666 , -2.993916  ]], dtype=float32), label_ids=array([1, 0, 0, ..., 2, 1, 0]), metrics={'test_loss': 1.2779923677444458, 'test_f1': 0.7199614421342672, 'test_recall': 0.720481119839072, 'test_runtime': 10.1967, 'test_samples_per_second': 186.236, 'test_steps_per_second': 23.341})"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = trainer.predict(tokenized_ds[\"test\"])\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c42a8ab3-93da-4162-967b-792ace795c70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1899"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1775df1a-f613-4c97-afab-87b3870abd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels = tokenized_ds[\"test\"]['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "26982e5f-dc6f-4bd5-a799-cad8e1e4728c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1899"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a7087657-3e18-4ece-aa42-d96bea860046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.80164   0.84217   0.82141       811\n",
      "           1    0.61569   0.55435   0.58341       552\n",
      "           2    0.74545   0.76493   0.75506       536\n",
      "\n",
      "    accuracy                        0.73670      1899\n",
      "   macro avg    0.72093   0.72048   0.71996      1899\n",
      "weighted avg    0.73173   0.73670   0.73350      1899\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted_labels = [np.argmax(pred) for pred in predictions[0]]\n",
    "classification_rep = classification_report(true_labels, predicted_labels, digits=5)\n",
    "\n",
    "print(classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "57814e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.load_state_dict(torch.load(f'./_BERT_epoch_3.model', map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ed4ae6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Error Analisys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b0f024-3661-4dcd-8dc5-8077e9db12a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "46bbd55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = ds['validation'].to_pandas()\n",
    "#val_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "737a62b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "918833cd06fc42678ce4d33c16007ae9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2374 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# step by step predictions on dataframe\n",
    "# We do this to view predictions in the pandas dataframe and easily filter them and perform error analysis.\n",
    "pred_final = []\n",
    "\n",
    "for i, row in tqdm(val_df.iterrows(), total=val_df.shape[0]):\n",
    "    predictions = []\n",
    "\n",
    "    text = row[\"text\"]\n",
    "    encoded_data_test_single = tokenizer.batch_encode_plus([text], \n",
    "    # add_special_tokens=config.add_special_tokens, \n",
    "    # return_attention_mask=config.return_attention_mask, \n",
    "    # pad_to_max_length=config.pad_to_max_length, \n",
    "    max_length=128,\n",
    "    # return_tensors=config.return_tensors\n",
    "    return_tensors=\"pt\"\n",
    "    )\n",
    "    input_ids_test = encoded_data_test_single['input_ids']\n",
    "    attention_masks_test = encoded_data_test_single['attention_mask']\n",
    "\n",
    "    \n",
    "    inputs = {'input_ids':      input_ids_test.to(device),\n",
    "              'attention_mask':attention_masks_test.to(device),\n",
    "             }\n",
    "\n",
    "    with torch.no_grad():        \n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    logits = outputs[0]\n",
    "    logits = logits.detach().cpu().numpy()\n",
    "    predictions.append(logits)\n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    pred_final.append(np.argmax(predictions, axis=1).flatten()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e2d5ea48-4899-4cb3-9027-0ea1cf46c0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add pred into val_df\n",
    "val_df[\"pred\"] = pred_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "aebc0161-59a5-4fc6-a34a-45f47f0416c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Add control column for easier wrong and right predictions\n",
    "control = val_df.pred.values == val_df.label.values\n",
    "val_df[\"control\"] = control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "76106d47-0012-41ec-9656-9d3227934bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering false predictions\n",
    "val_df = val_df[val_df.control == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ecdd05ba-780e-417f-a155-812850af1b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label to intent mapping\n",
    "name2label = {\"Negative\":0,\n",
    "              \"Neutral\":1,\n",
    "             \"Positive\":2\n",
    "             }\n",
    "label2name = {v: k for k, v in name2label.items()}\n",
    "\n",
    "val_df[\"pred_name\"] = val_df.pred.apply(lambda x: label2name.get(x)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0e076559-81d8-4997-979e-330b1e15f200",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# We create a confusion matrix to better observe the classes that the model confuses.\n",
    "pred_name_values = val_df.pred_name.values\n",
    "label_values = val_df.label_name.values\n",
    "confmat = confusion_matrix(label_values, pred_name_values, labels=list(name2label.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "86229af8-4484-4551-bfca-7280b8eab020",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0, 215,  38],\n",
       "       [128,   0, 137],\n",
       "       [ 50, 170,   0]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a282fc0e-f045-430b-9126-194627f8c043",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>Positive</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Negative</th>\n",
       "      <td>0</td>\n",
       "      <td>215</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neutral</th>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Positive</th>\n",
       "      <td>50</td>\n",
       "      <td>170</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0     Negative  Neutral  Positive\n",
       "row_0                                \n",
       "Negative         0      215        38\n",
       "Neutral        128        0       137\n",
       "Positive        50      170         0"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_confusion_val = pd.crosstab(label_values, pred_name_values)\n",
    "df_confusion_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8e6e4c35-1a05-44f2-8b40-a7a6dee7ae49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save confissuan matrix df\n",
    "df_confusion_val.to_csv(\"val_df_confusion.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab28ef2-630e-45b3-9552-ee2e42e66160",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c79614ce-e047-449c-b3a8-83ed2becfc20",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "04ce937d-9bfc-43c1-88a9-d99a4c7f56ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['no yuli con eso se va con pendeivis  emoji cara decepcionada emoji',\n",
       " 'este es m치s bruto... cosas que necesita el  per칰 obio que se importara.. todo lo que tienes que decir para que gan칠  kk.. mariposa  emoji mariposa emoji  gorda... !',\n",
       " 'bakan tu video pero el chambar es riko pero para puesto 1 no va ah, el caldo blanco es mucho mas sabroso, sin mencionar la infinidad de sopas, caldos y chupes q se prepara en arequipa como el chaque de tripas, el puchero o el timpo de rabos etc etc, saludos compare  emoji pulgar hacia arriba emoji',\n",
       " 'no sabes que hacer para llamar la atenci칩n para que te dean bola en tus canciones copiada  emoji cara vomitando emoji  emoji cara vomitando emoji  emoji cara vomitando emoji',\n",
       " 'pe chino dame chamba mano, almenos pa limpiarte las tabas :v emoji cara de por favor emoji',\n",
       " 'casaca de cuero?? c칩mo abran sudado esas alicias  emoji cara revolvi칠ndose de la risa emoji  emoji cara revolvi칠ndose de la risa emoji  emoji cara revolvi칠ndose de la risa emoji',\n",
       " 'marcela jurado ramos ya kisieras llegarle a ala mugre de las pezu침as tu a maria pia copello  emoji cara llorando de risa emoji  emoji cara llorando de risa emoji  emoji cara revolvi칠ndose de la risa emoji',\n",
       " 'jajja su aparato!!!  emoji cara revolvi칠ndose de la risa emoji',\n",
       " '游뱡\\u200d no les hagas caso, solo son envidiosos porque ellos seguro no conocen otro idioma que el espa침ol; yo s칠 que si lo hablas  emoji pulgar hacia arriba emoji . veo mucho anim칠 japon칠s  emoji cara radiante con ojos sonrientes emoji . yo hablo franc칠s, alem치n y espa침ol y me vale verga la gente envidiosa que no acepta los conocimientos de los dem치s.  emoji cara gui침ando el ojo emoji  치nimo y sigue con tus lecciones, a mi me encanta tu blog.',\n",
       " 'el valiente que recibi칩 un mill칩n de cocos para fallar a favor de la impugnaci칩n de las ratas que apoyas rid칤culo, pedo...  emoji cara revolvi칠ndose de la risa emoji  emoji cara revolvi칠ndose de la risa emoji  emoji cara revolvi칠ndose de la risa emoji',\n",
       " 'tu hermano gemelo manolo... sobrado la haces como su doble..   emoji cara con mano sobre la boca emoji  emoji cara con mano sobre la boca emoji',\n",
       " 'hablando huevadas de huevones jaja  emoji cara revolvi칠ndose de la risa emoji',\n",
       " 'los 칰nicos babosos ser치n los que sigan viendo tu programa... emoji cara llorando de risa emoji',\n",
       " 'tan bella esa carita de la japeruana mamacita... emoji cara sonriendo con ojos de coraz칩n emoji',\n",
       " 'emoji cara de payaso emoji  emoji cara de payaso emoji  emoji cara de payaso emoji  nunca fuistes arquero mantequilla',\n",
       " 'con tanta nececidad que salen de su pa칤s.y no entiendo porqu칠 esa maldad con las personas que no tiene culpa de su desgracia..esa  ira. ..entre todos  la pueden utilizar contra su presidente maduro..a ese es que le tienen que cobrar. lo malo que les pasa emoji cara cabreada emoji',\n",
       " 'angello ormaeche chris ormaeche ruiz miguel mejia que suba el chamo  emoji cara revolvi칠ndose de la risa emoji',\n",
       " 'los pallares verdes son lo mejor del mundo!!  emoji cara feliz con ojos sonrientes emoji',\n",
       " 'jaja as칤 me sent칤 esa vez que se juntaron evelyn leidy y tu amiga vane... y yo tratando de tomar mi sopita de pollo emoji cara llorando emoji',\n",
       " 'ay querido gaston trajiste a mi mente quizas unos de los mas gratos recuerdos de mi ni침ez e incluso juventud el chifa! los uribe somos de ancestro serrano pero nos encanta el chifa! creo q todo inicia con mi abuelo pedro uribe en palpa hacienda al norte chico...el llevaba o hacia chifa en casa, mis padres nos llevaron a nosotros tambi칠n en huaral o chancay a los mismos chifas esos que dices de las cortinas...y luego yo he llevado a mi esposo y mi hijo a lo mismo ( se tambien que a  todos mis primos les encanta el chifa) y ahora aun en eeuu mi hijo de 16 a침os el 칰nico plato que sabe preparar y le sale deli porque le he ense침ado como tu dices a saltear es el chaufa! bendito tu peruano de altura que nos regalas estos momentos de enorme a침oranza y alegria!!! pd: y ya te he dicho si no cocinas escribe!!!...si bien la cocina peruana gano a su mejor embajador...estoy segura que la literatura peruana esta un poco resentida! emoji cara con mano sobre la boca emoji',\n",
       " 'dejen gobernar carj!!! solo defienden los intereses de los grupo de poder econ칩mico acostumbrados a manejar al per칰 como su chacra emoji cara con s칤mbolos en la boca emoji  emoji cara con s칤mbolos en la boca emoji  emoji cara con s칤mbolos en la boca emoji',\n",
       " 'tienes un estilo 칰nico bro yo fui con mi hijo x hay x camana y pucha ve tantas cosas cl치sicas y le gusta saludos  emoji cara sonriendo ligeramente emoji',\n",
       " 'https://url/  siga su propio consejo se침or ortiz. deje de ser una vieja avinagrada, que esta en el balc칩n, viendo quien le saca la vuelta a quien, para tirar dedo, para chismear, para generar la intriga, la maledicencia, el veneno, no pues  emoji cara sonriendo con sudor fr칤o emoji  no seas como una de esas viejas chismosas, no vale la pena.   sea congruente se침or ortiz  emoji cara con mano sobre la boca emoji',\n",
       " 'pa concha, escritor quieres ser쯘scritor de qu칠?',\n",
       " 'a poco escuch칩se el rumor de bestias al galope',\n",
       " 'amar칤a amar칤a amar칤a viajar junto con mi mejor amiga al norte, despu칠s de tanto estr칠s de los finales de la u siento que nos merecemos un viajecito para relajar y de paso chapar un poquito de sol que estamos maaas blancas  emoji cara con ojos en blanco emoji  emoji cara con ojos en blanco emoji  emoji cara con ojos en blanco emoji',\n",
       " 'c칩mo dir칤a mi brother iv치n: sarta de ensaladas  emoji cara revolvi칠ndose de la risa emoji !',\n",
       " 'adharaalmora cuando nos juntamos a rajar  emoji cara llorando de risa emoji',\n",
       " 'jj note iguales ni alas pezu침as de  magali emoji cara revolvi칠ndose de la risa emoji  emoji cara revolvi칠ndose de la risa emoji  emoji cara revolvi칠ndose de la risa emoji  esta con ganas de facturar',\n",
       " 'estoy esperando los dichosos audios bomba  y nada ya me cans칠 de esperar tanto les duele que un serrano sea tu presidente acostumbrate pedro castillo terrones es el presidente del pueblo peruano arriva per칰  emoji bandera per칰 emoji  emoji bandera per칰 emoji  emoji pulgar hacia arriba emoji  emoji pulgar hacia arriba emoji  emoji pulgar hacia arriba emoji']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_ds['train']['text'][:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6c8f59ba-bb88-4992-ac2b-fbe58afe4158",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'config' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[56], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m encoded_data_test \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mbatch_encode_plus(\n\u001b[1;32m      2\u001b[0m     val_df\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39mvalues, \n\u001b[0;32m----> 3\u001b[0m     add_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[43mconfig\u001b[49m\u001b[38;5;241m.\u001b[39madd_special_tokens, \n\u001b[1;32m      4\u001b[0m     return_attention_mask\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mreturn_attention_mask, \n\u001b[1;32m      5\u001b[0m     pad_to_max_length\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpad_to_max_length,\n\u001b[1;32m      6\u001b[0m     max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m, \n\u001b[1;32m      7\u001b[0m     return_tensors\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mreturn_tensors\n\u001b[1;32m      8\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'config' is not defined"
     ]
    }
   ],
   "source": [
    "encoded_data_test = tokenizer.batch_encode_plus(\n",
    "    val_df.text.values, \n",
    "    add_special_tokens=config.add_special_tokens, \n",
    "    return_attention_mask=config.return_attention_mask, \n",
    "    pad_to_max_length=config.pad_to_max_length,\n",
    "    max_length=128, \n",
    "    return_tensors=config.return_tensors\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6b284f-e6f6-4232-a1f0-15bda7fc19b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "926977d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate the Model Qualitatively (Human Evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7faa99dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate the Model Quantitatively (with F1 Metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be445d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c839bdd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = val_df[0:20]['text']\n",
    "human_baseline_labels = val_df[0:20]['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebbb4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb03153f",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_baseline_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a070557c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#original_model_summaries = []\n",
    "model_classifications = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8436a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, text in enumerate(texts):\n",
    "    input_ids = tokenizer(text, return_tensors=\"pt\", max_length=128).input_ids.to('cuda')\n",
    "    logits = model(input_ids).logits\n",
    "    probabilities = logits.softmax(dim=-1).tolist()[0]\n",
    "    model_classifications.append(np.argmax(probabilities).flatten()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1a671b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_classifications"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
